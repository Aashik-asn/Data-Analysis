# -*- coding: utf-8 -*-
"""Vader and textblob.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FDk_Guuor_Mo04W6ebHqVguFKjbdT5mi
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import nltk
nltk.download('vader_lexicon')  # Download the required lexicon
from nltk.sentiment import SentimentIntensityAnalyzer

sia = SentimentIntensityAnalyzer()

from textblob import TextBlob
from tqdm.notebook import tqdm
from sklearn.metrics import accuracy_score

plt.style.use('ggplot')

from google.colab import drive
drive.mount('/content/drive')

#df = pd.read_csv('Reviews.csv')
df = pd.read_csv('/content/drive/MyDrive/Proj/Code(Jupyter)/Reviews.csv')
print(df.shape)
df = df.head(10000) #To minimise the values
print(df.shape)
print(df)

df.describe()

print(df.info()) # to check all columns are non-empty

uniqId = len(df["ProductId"].unique())
print("Total Number of ProductID : " + str (len(df["ProductId"])))
print("Number of Unique ProductID : " + str (uniqId))

ax=df['Score'].value_counts().sort_index().plot(kind='bar',
                                             title = 'Count of reviews by stars',
                                             figsize = (6, 5))
ax.set_xlabel('Review Stars')
plt.show()

#Creating a dict res1 which consist of sentiment based on the reviewer rating
res={}
for i, row in tqdm(df.iterrows(), total = len(df)):
    score = row['Score']
    myid = row['Id']
    if score>3:
        res[myid] = {'sentiment': "Positive"}
    elif score<3:
        res[myid] = {'sentiment': "Negative"}
    else:
        res[myid] = {'sentiment': "Neutral"}
res

manual=pd.DataFrame(res).T #dict to dataframe , .T is transpose
manual = manual.reset_index().rename(columns={'index': 'Id'})
print(manual)

df=df.merge(manual)
df.head()

example = df['Text'][50]
print(example)

#!pip uninstall nltk
#!pip install nltk==3.8.1
#downgraded nltk

import nltk
nltk.download('punkt')#for wordtokenizer
print(nltk.data.path)

tokens = nltk.word_tokenize(example, language='english', preserve_line=True)#splitting sentence into words
print(tokens)

import nltk
nltk.download('averaged_perceptron_tagger')

tagged=nltk.pos_tag(tokens) #part of speech tag
tagged[:10]

#nltk.download('words')
#nltk.download('stopwords')
#nltk.download('maxent_ne_chunker')
#not necessary but if required

entities = nltk.chunk.ne_chunk(tagged) #To get below format for furthur work on
print(entities)

from nltk.sentiment.vader import SentimentIntensityAnalyzer # To use Vader Model
from tqdm.notebook import tqdm #Progress bar
sia = SentimentIntensityAnalyzer()

print(sia.polarity_scores('I am so happy'))#Sentiment score
print(sia.polarity_scores('I am so happy!!!')) #intensity on '!'
print(sia.polarity_scores(':)'))

print(sia.polarity_scores('I am so sad'))
print(sia.polarity_scores('I am so sad!!!'))
print(sia.polarity_scores(':('))

print(example)
print(sia.polarity_scores(example))

vad_res={}
#for i,row in (df.iterrows()): #we can also use this
#tqdm is used to display that progress(total gives the denom '500')
for i, row in tqdm(df.iterrows(),total = len(df)):
    text = row['Text']
    myid = row['Id']
    vad_res[myid] = sia.polarity_scores(text)
vad_res

vaders = pd.DataFrame(vad_res).T #.T interchange the rows and columns
vaders = vaders.reset_index().rename(columns={'index': 'Id'})
#Here index has renamed as Id, since we need a same column while merging
vaders = vaders.merge(df) #merging df dataset in vaders
vaders.head()

df = df.merge(vaders)
df.head()

ax = sns.barplot(data=vaders, x='Score', y='compound')
#Compound score is the avg polarity score
ax.set_title('Compound Score by Amazon Star Reviews')
plt.show()

fig, axs = plt.subplots(1, 3, figsize=(15,5))
sns.barplot(data=vaders, x='Score', y='pos', ax = axs[0])
sns.barplot(data=vaders, x='Score', y='neu', ax = axs[1])
sns.barplot(data=vaders, x='Score', y='neg', ax = axs[2])
axs[0].set_title('Positive')
axs[1].set_title('Neutral')
axs[2].set_title('Negative')
plt.tight_layout() #To avoid Overlap
plt.show()

#Creating a dict res1 which consist of sentiment based on the vader polarity score
res1={}
for i, row in tqdm(df.iterrows(), total = len(df)):
    score = row['compound']
    myid = row['Id']
    if score>=0.05:
        res1[myid] = {'vader_sentiment': "Positive"}
    elif score<=-0.05:
        res1[myid] = {'vader_sentiment': "Negative"}
    else:
        res1[myid] = {'vader_sentiment': "Neutral"}
res1

vaderauto = pd.DataFrame(res1).T #dict to dataframe
vaderauto = vaderauto.reset_index().rename(columns={'index': 'Id'})
df = df.merge(vaderauto, how='left')
df.head()

from textblob import TextBlob

print(TextBlob('I am so happy').sentiment)#Sentiment score
print(TextBlob('I am so happy!!!').sentiment) #intensity on '!'
print(TextBlob(':)').sentiment)

print(TextBlob('I am so sad').sentiment)
print(TextBlob('I am so sad!!!').sentiment)
print(TextBlob(':(').sentiment)

print(example)
print(TextBlob(example).sentiment)

tb_res={}
#for i,row in (df.iterrows()): #we can also use this
#tqdm is used to display that progress(total gives the denom '500')
for i, row in tqdm(df.iterrows(),total = len(df)):
    text = row['Text']
    myid = row['Id']
    temp={}
    temp['polarity']=((TextBlob(text)).sentiment)[0]
    tb_res[myid] = temp
tb_res

textblobs = pd.DataFrame(tb_res).T
textblobs = textblobs.reset_index().rename(columns={'index': 'Id'})
textblobs = textblobs.merge(df, how='left')
textblobs.head()

df = df.merge(textblobs, how='left')
df.head()

ax1 = sns.barplot(data=textblobs, x='Score', y='polarity')
ax.set_title('Polarity Score by Amazon Star Reviews')
plt.show()

#Creating a dict res1 which consist of sentiment based on the textblob polarity score
res2={}
for i, row in tqdm(df.iterrows(), total = len(df)):
    score = row['polarity']
    myid = row['Id']
    if score>=0.05:
        res2[myid] = {'textblob_sentiment': "Positive"}
    elif score<=-0.05:
        res2[myid] = {'textblob_sentiment': "Negative"}
    else:
        res2[myid] = {'textblob_sentiment': "Neutral"}
res2

tbauto = pd.DataFrame(res2).T #dict to dataframe
tbauto = tbauto.reset_index().rename(columns={'index': 'Id'})
df = df.merge(tbauto, how='left')
df.head()

plt.subplot(1,3,1)
df['sentiment'].value_counts().plot(kind='bar',
                                    title = 'Count of reviews by stars',
                                    figsize = (20, 5))
plt.subplot(1,3,2)
df['vader_sentiment'].value_counts().plot(kind='bar',
                                    title = 'Count of reviews by reviews(vader)',
                                    figsize = (20, 5))
plt.subplot(1,3,3)
df['textblob_sentiment'].value_counts().plot(kind='bar',
                                    title = 'Count of reviews by reviews(textblob)',
                                    figsize = (20, 5))
plt.show()

mylabels = ["positive","negative","neutral"]
plt.subplots(1,3,figsize=(9,9))
plt.subplot(1,3,1)
x=df['sentiment'].value_counts()/df.shape[0]
plt.pie(x, shadow = True, autopct="%0.2f%%",labels=mylabels)
plt.title('Sentiment')

plt.subplot(1,3,2)
y=df['vader_sentiment'].value_counts()/df.shape[0]
plt.pie(y, shadow = True, autopct="%0.2f%%",labels=mylabels)
plt.title('Vader Sentiment')

plt.subplot(1,3,3)
z=df['textblob_sentiment'].value_counts()/df.shape[0]
plt.pie(z, shadow = True, autopct="%0.2f%%",labels=mylabels)
plt.title('TextBlob Sentiment')

plt.tight_layout()
plt.show()

from sklearn.metrics import accuracy_score

score=accuracy_score(df['sentiment'],df['textblob_sentiment'])
print("The accuracy of the user rating and user reviewtext(Textblob) are {score}% ".format(score=score*100))

score=accuracy_score(df['sentiment'],df['vader_sentiment'])
print("The accuracy of the user rating and user reviewtext(Vader) are {score}% ".format(score=score*100))

score=round(accuracy_score(df['textblob_sentiment'],df['vader_sentiment']),2)
print("The accuracy of the user reviewtext(textblob) and user reviewtext(Vader) are {score}% ".format(score=score*100))